# MODULE
processing.module.enabled=true

# PROCESSING
documents.processing.enabled=false
documents.processing.stemming.enabled=true
documents.processing.batch.size=50
documents.processing.batch.pause=5000
documents.processing.parallelism.factor=2
documents.processing.downloaded.date.min=
# Number of required connections to the database for data.messie: # available cores * documents.processing.parallelism.factor * 2

# CLEANING
boilerpipe.extractor=ArticleExtractor
#boilerpipe.extractor=ArticleSentencesExtractor
#boilerpipe.extractor=CanolaExtractor
#boilerpipe.extractor=DefaultExtractor
#boilerpipe.extractor=KeepEverythingExtractor
#boilerpipe.extractor=KeepEverythingWithMinKWordsExtractor
#boilerpipe.extractor.minK=0
#boilerpipe.extractor=LargestContentExtractor
#boilerpipe.extractor=NumWordsRulesExtractor

# NLP
pos.model=nlp/german-fast.tagger
#pos.model=nlp/german-hgc.tagger
ner.model=nlp/hgc_175m_600.crf.ser.gz

# FULLTEXT
documents.indexing.rebuildIndexAtStartup=false
documents.indexing.batch.size=50
documents.reindexing.enabled=false
documents.reindexing.pause=10000
